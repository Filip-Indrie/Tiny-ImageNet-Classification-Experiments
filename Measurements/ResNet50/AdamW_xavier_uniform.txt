==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Sequential                               [1, 200]                  --
├─Sequential: 1-1                        [1, 64, 32, 32]           --
│    └─Conv2d: 2-1                       [1, 64, 64, 64]           9,472
│    └─BatchNorm2d: 2-2                  [1, 64, 64, 64]           128
│    └─ReLU: 2-3                         [1, 64, 64, 64]           --
│    └─MaxPool2d: 2-4                    [1, 64, 32, 32]           --
├─Sequential: 1-2                        [1, 256, 32, 32]          --
│    └─ResidualBottleneck: 2-5           [1, 256, 32, 32]          --
│    │    └─Conv2d: 3-1                  [1, 64, 32, 32]           4,160
│    │    └─BatchNorm2d: 3-2             [1, 64, 32, 32]           128
│    │    └─ReLU: 3-3                    [1, 64, 32, 32]           --
│    │    └─Conv2d: 3-4                  [1, 64, 32, 32]           36,928
│    │    └─BatchNorm2d: 3-5             [1, 64, 32, 32]           128
│    │    └─ReLU: 3-6                    [1, 64, 32, 32]           --
│    │    └─Conv2d: 3-7                  [1, 256, 32, 32]          16,640
│    │    └─BatchNorm2d: 3-8             [1, 256, 32, 32]          512
│    │    └─Sequential: 3-9              [1, 256, 32, 32]          17,152
│    │    └─ReLU: 3-10                   [1, 256, 32, 32]          --
│    └─ResidualBottleneck: 2-6           [1, 256, 32, 32]          --
│    │    └─Conv2d: 3-11                 [1, 64, 32, 32]           16,448
│    │    └─BatchNorm2d: 3-12            [1, 64, 32, 32]           128
│    │    └─ReLU: 3-13                   [1, 64, 32, 32]           --
│    │    └─Conv2d: 3-14                 [1, 64, 32, 32]           36,928
│    │    └─BatchNorm2d: 3-15            [1, 64, 32, 32]           128
│    │    └─ReLU: 3-16                   [1, 64, 32, 32]           --
│    │    └─Conv2d: 3-17                 [1, 256, 32, 32]          16,640
│    │    └─BatchNorm2d: 3-18            [1, 256, 32, 32]          512
│    │    └─ReLU: 3-19                   [1, 256, 32, 32]          --
│    └─ResidualBottleneck: 2-7           [1, 256, 32, 32]          --
│    │    └─Conv2d: 3-20                 [1, 64, 32, 32]           16,448
│    │    └─BatchNorm2d: 3-21            [1, 64, 32, 32]           128
│    │    └─ReLU: 3-22                   [1, 64, 32, 32]           --
│    │    └─Conv2d: 3-23                 [1, 64, 32, 32]           36,928
│    │    └─BatchNorm2d: 3-24            [1, 64, 32, 32]           128
│    │    └─ReLU: 3-25                   [1, 64, 32, 32]           --
│    │    └─Conv2d: 3-26                 [1, 256, 32, 32]          16,640
│    │    └─BatchNorm2d: 3-27            [1, 256, 32, 32]          512
│    │    └─ReLU: 3-28                   [1, 256, 32, 32]          --
├─Sequential: 1-3                        [1, 512, 16, 16]          --
│    └─ResidualBottleneck: 2-8           [1, 512, 16, 16]          --
│    │    └─Conv2d: 3-29                 [1, 128, 32, 32]          32,896
│    │    └─BatchNorm2d: 3-30            [1, 128, 32, 32]          256
│    │    └─ReLU: 3-31                   [1, 128, 32, 32]          --
│    │    └─Conv2d: 3-32                 [1, 128, 16, 16]          147,584
│    │    └─BatchNorm2d: 3-33            [1, 128, 16, 16]          256
│    │    └─ReLU: 3-34                   [1, 128, 16, 16]          --
│    │    └─Conv2d: 3-35                 [1, 512, 16, 16]          66,048
│    │    └─BatchNorm2d: 3-36            [1, 512, 16, 16]          1,024
│    │    └─Sequential: 3-37             [1, 512, 16, 16]          132,608
│    │    └─ReLU: 3-38                   [1, 512, 16, 16]          --
│    └─ResidualBottleneck: 2-9           [1, 512, 16, 16]          --
│    │    └─Conv2d: 3-39                 [1, 128, 16, 16]          65,664
│    │    └─BatchNorm2d: 3-40            [1, 128, 16, 16]          256
│    │    └─ReLU: 3-41                   [1, 128, 16, 16]          --
│    │    └─Conv2d: 3-42                 [1, 128, 16, 16]          147,584
│    │    └─BatchNorm2d: 3-43            [1, 128, 16, 16]          256
│    │    └─ReLU: 3-44                   [1, 128, 16, 16]          --
│    │    └─Conv2d: 3-45                 [1, 512, 16, 16]          66,048
│    │    └─BatchNorm2d: 3-46            [1, 512, 16, 16]          1,024
│    │    └─ReLU: 3-47                   [1, 512, 16, 16]          --
│    └─ResidualBottleneck: 2-10          [1, 512, 16, 16]          --
│    │    └─Conv2d: 3-48                 [1, 128, 16, 16]          65,664
│    │    └─BatchNorm2d: 3-49            [1, 128, 16, 16]          256
│    │    └─ReLU: 3-50                   [1, 128, 16, 16]          --
│    │    └─Conv2d: 3-51                 [1, 128, 16, 16]          147,584
│    │    └─BatchNorm2d: 3-52            [1, 128, 16, 16]          256
│    │    └─ReLU: 3-53                   [1, 128, 16, 16]          --
│    │    └─Conv2d: 3-54                 [1, 512, 16, 16]          66,048
│    │    └─BatchNorm2d: 3-55            [1, 512, 16, 16]          1,024
│    │    └─ReLU: 3-56                   [1, 512, 16, 16]          --
│    └─ResidualBottleneck: 2-11          [1, 512, 16, 16]          --
│    │    └─Conv2d: 3-57                 [1, 128, 16, 16]          65,664
│    │    └─BatchNorm2d: 3-58            [1, 128, 16, 16]          256
│    │    └─ReLU: 3-59                   [1, 128, 16, 16]          --
│    │    └─Conv2d: 3-60                 [1, 128, 16, 16]          147,584
│    │    └─BatchNorm2d: 3-61            [1, 128, 16, 16]          256
│    │    └─ReLU: 3-62                   [1, 128, 16, 16]          --
│    │    └─Conv2d: 3-63                 [1, 512, 16, 16]          66,048
│    │    └─BatchNorm2d: 3-64            [1, 512, 16, 16]          1,024
│    │    └─ReLU: 3-65                   [1, 512, 16, 16]          --
├─Sequential: 1-4                        [1, 1024, 8, 8]           --
│    └─ResidualBottleneck: 2-12          [1, 1024, 8, 8]           --
│    │    └─Conv2d: 3-66                 [1, 256, 16, 16]          131,328
│    │    └─BatchNorm2d: 3-67            [1, 256, 16, 16]          512
│    │    └─ReLU: 3-68                   [1, 256, 16, 16]          --
│    │    └─Conv2d: 3-69                 [1, 256, 8, 8]            590,080
│    │    └─BatchNorm2d: 3-70            [1, 256, 8, 8]            512
│    │    └─ReLU: 3-71                   [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-72                 [1, 1024, 8, 8]           263,168
│    │    └─BatchNorm2d: 3-73            [1, 1024, 8, 8]           2,048
│    │    └─Sequential: 3-74             [1, 1024, 8, 8]           527,360
│    │    └─ReLU: 3-75                   [1, 1024, 8, 8]           --
│    └─ResidualBottleneck: 2-13          [1, 1024, 8, 8]           --
│    │    └─Conv2d: 3-76                 [1, 256, 8, 8]            262,400
│    │    └─BatchNorm2d: 3-77            [1, 256, 8, 8]            512
│    │    └─ReLU: 3-78                   [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-79                 [1, 256, 8, 8]            590,080
│    │    └─BatchNorm2d: 3-80            [1, 256, 8, 8]            512
│    │    └─ReLU: 3-81                   [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-82                 [1, 1024, 8, 8]           263,168
│    │    └─BatchNorm2d: 3-83            [1, 1024, 8, 8]           2,048
│    │    └─ReLU: 3-84                   [1, 1024, 8, 8]           --
│    └─ResidualBottleneck: 2-14          [1, 1024, 8, 8]           --
│    │    └─Conv2d: 3-85                 [1, 256, 8, 8]            262,400
│    │    └─BatchNorm2d: 3-86            [1, 256, 8, 8]            512
│    │    └─ReLU: 3-87                   [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-88                 [1, 256, 8, 8]            590,080
│    │    └─BatchNorm2d: 3-89            [1, 256, 8, 8]            512
│    │    └─ReLU: 3-90                   [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-91                 [1, 1024, 8, 8]           263,168
│    │    └─BatchNorm2d: 3-92            [1, 1024, 8, 8]           2,048
│    │    └─ReLU: 3-93                   [1, 1024, 8, 8]           --
│    └─ResidualBottleneck: 2-15          [1, 1024, 8, 8]           --
│    │    └─Conv2d: 3-94                 [1, 256, 8, 8]            262,400
│    │    └─BatchNorm2d: 3-95            [1, 256, 8, 8]            512
│    │    └─ReLU: 3-96                   [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-97                 [1, 256, 8, 8]            590,080
│    │    └─BatchNorm2d: 3-98            [1, 256, 8, 8]            512
│    │    └─ReLU: 3-99                   [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-100                [1, 1024, 8, 8]           263,168
│    │    └─BatchNorm2d: 3-101           [1, 1024, 8, 8]           2,048
│    │    └─ReLU: 3-102                  [1, 1024, 8, 8]           --
│    └─ResidualBottleneck: 2-16          [1, 1024, 8, 8]           --
│    │    └─Conv2d: 3-103                [1, 256, 8, 8]            262,400
│    │    └─BatchNorm2d: 3-104           [1, 256, 8, 8]            512
│    │    └─ReLU: 3-105                  [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-106                [1, 256, 8, 8]            590,080
│    │    └─BatchNorm2d: 3-107           [1, 256, 8, 8]            512
│    │    └─ReLU: 3-108                  [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-109                [1, 1024, 8, 8]           263,168
│    │    └─BatchNorm2d: 3-110           [1, 1024, 8, 8]           2,048
│    │    └─ReLU: 3-111                  [1, 1024, 8, 8]           --
│    └─ResidualBottleneck: 2-17          [1, 1024, 8, 8]           --
│    │    └─Conv2d: 3-112                [1, 256, 8, 8]            262,400
│    │    └─BatchNorm2d: 3-113           [1, 256, 8, 8]            512
│    │    └─ReLU: 3-114                  [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-115                [1, 256, 8, 8]            590,080
│    │    └─BatchNorm2d: 3-116           [1, 256, 8, 8]            512
│    │    └─ReLU: 3-117                  [1, 256, 8, 8]            --
│    │    └─Conv2d: 3-118                [1, 1024, 8, 8]           263,168
│    │    └─BatchNorm2d: 3-119           [1, 1024, 8, 8]           2,048
│    │    └─ReLU: 3-120                  [1, 1024, 8, 8]           --
├─Sequential: 1-5                        [1, 2048, 4, 4]           --
│    └─ResidualBottleneck: 2-18          [1, 2048, 4, 4]           --
│    │    └─Conv2d: 3-121                [1, 512, 8, 8]            524,800
│    │    └─BatchNorm2d: 3-122           [1, 512, 8, 8]            1,024
│    │    └─ReLU: 3-123                  [1, 512, 8, 8]            --
│    │    └─Conv2d: 3-124                [1, 512, 4, 4]            2,359,808
│    │    └─BatchNorm2d: 3-125           [1, 512, 4, 4]            1,024
│    │    └─ReLU: 3-126                  [1, 512, 4, 4]            --
│    │    └─Conv2d: 3-127                [1, 2048, 4, 4]           1,050,624
│    │    └─BatchNorm2d: 3-128           [1, 2048, 4, 4]           4,096
│    │    └─Sequential: 3-129            [1, 2048, 4, 4]           2,103,296
│    │    └─ReLU: 3-130                  [1, 2048, 4, 4]           --
│    └─ResidualBottleneck: 2-19          [1, 2048, 4, 4]           --
│    │    └─Conv2d: 3-131                [1, 512, 4, 4]            1,049,088
│    │    └─BatchNorm2d: 3-132           [1, 512, 4, 4]            1,024
│    │    └─ReLU: 3-133                  [1, 512, 4, 4]            --
│    │    └─Conv2d: 3-134                [1, 512, 4, 4]            2,359,808
│    │    └─BatchNorm2d: 3-135           [1, 512, 4, 4]            1,024
│    │    └─ReLU: 3-136                  [1, 512, 4, 4]            --
│    │    └─Conv2d: 3-137                [1, 2048, 4, 4]           1,050,624
│    │    └─BatchNorm2d: 3-138           [1, 2048, 4, 4]           4,096
│    │    └─ReLU: 3-139                  [1, 2048, 4, 4]           --
│    └─ResidualBottleneck: 2-20          [1, 2048, 4, 4]           --
│    │    └─Conv2d: 3-140                [1, 512, 4, 4]            1,049,088
│    │    └─BatchNorm2d: 3-141           [1, 512, 4, 4]            1,024
│    │    └─ReLU: 3-142                  [1, 512, 4, 4]            --
│    │    └─Conv2d: 3-143                [1, 512, 4, 4]            2,359,808
│    │    └─BatchNorm2d: 3-144           [1, 512, 4, 4]            1,024
│    │    └─ReLU: 3-145                  [1, 512, 4, 4]            --
│    │    └─Conv2d: 3-146                [1, 2048, 4, 4]           1,050,624
│    │    └─BatchNorm2d: 3-147           [1, 2048, 4, 4]           4,096
│    │    └─ReLU: 3-148                  [1, 2048, 4, 4]           --
├─AdaptiveAvgPool2d: 1-6                 [1, 2048, 1, 1]           --
├─Flatten: 1-7                           [1, 2048]                 --
├─Linear: 1-8                            [1, 200]                  409,800
==========================================================================================
Total params: 23,944,392
Trainable params: 23,944,392
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 1.34
==========================================================================================
Input size (MB): 0.20
Forward/backward pass size (MB): 58.07
Params size (MB): 95.78
Estimated Total Size (MB): 154.04
==========================================================================================

Epoch 1, Train loss 4.71, Train accuracy 6.17, Validation loss 5.20, Validation accuracy 10.43
Epoch 2, Train loss 3.83, Train accuracy 16.20, Validation loss 4.92, Validation accuracy 18.04
Epoch 3, Train loss 3.31, Train accuracy 24.31, Validation loss 3.28, Validation accuracy 27.85
Epoch 4, Train loss 2.98, Train accuracy 30.69, Validation loss 3.51, Validation accuracy 30.05
Epoch 5, Train loss 2.73, Train accuracy 35.20, Validation loss 2.70, Validation accuracy 36.62
Epoch 6, Train loss 2.47, Train accuracy 40.48, Validation loss 2.58, Validation accuracy 39.68
Epoch 7, Train loss 2.24, Train accuracy 45.03, Validation loss 2.39, Validation accuracy 42.89
Epoch 8, Train loss 2.06, Train accuracy 48.84, Validation loss 2.32, Validation accuracy 44.70
Epoch 9, Train loss 1.88, Train accuracy 52.75, Validation loss 2.25, Validation accuracy 46.26
Epoch 10, Train loss 1.71, Train accuracy 56.22, Validation loss 2.22, Validation accuracy 47.42
Epoch 11, Train loss 1.55, Train accuracy 59.77, Validation loss 2.36, Validation accuracy 47.22
Epoch 12, Train loss 1.40, Train accuracy 62.89, Validation loss 2.13, Validation accuracy 50.09
Epoch 13, Train loss 1.25, Train accuracy 66.35, Validation loss 2.15, Validation accuracy 49.60
Epoch 14, Train loss 1.12, Train accuracy 69.49, Validation loss 2.16, Validation accuracy 50.40
Epoch 15, Train loss 0.98, Train accuracy 72.88, Validation loss 2.25, Validation accuracy 50.34
Epoch 16, Train loss 0.86, Train accuracy 75.67, Validation loss 2.34, Validation accuracy 50.07
Epoch 17, Train loss 0.76, Train accuracy 78.26, Validation loss 2.43, Validation accuracy 49.98
Epoch 18, Train loss 0.66, Train accuracy 80.92, Validation loss 2.37, Validation accuracy 50.58
Epoch 19, Train loss 0.58, Train accuracy 82.94, Validation loss 2.52, Validation accuracy 50.36
Epoch 20, Train loss 0.53, Train accuracy 84.36, Validation loss 2.45, Validation accuracy 51.04
Epoch 21, Train loss 0.47, Train accuracy 86.15, Validation loss 2.53, Validation accuracy 50.89
Epoch 22, Train loss 0.42, Train accuracy 87.55, Validation loss 2.55, Validation accuracy 51.04
Epoch 23, Train loss 0.39, Train accuracy 88.57, Validation loss 2.65, Validation accuracy 50.95
Epoch 24, Train loss 0.36, Train accuracy 89.35, Validation loss 2.70, Validation accuracy 50.52
Epoch 25, Train loss 0.33, Train accuracy 90.05, Validation loss 2.63, Validation accuracy 50.67
Epoch 26, Train loss 0.31, Train accuracy 90.82, Validation loss 2.68, Validation accuracy 50.58
Epoch 27, Train loss 0.29, Train accuracy 91.30, Validation loss 2.73, Validation accuracy 50.69
Epoch 28, Train loss 0.28, Train accuracy 91.68, Validation loss 2.70, Validation accuracy 50.83
Epoch 29, Train loss 0.26, Train accuracy 92.26, Validation loss 2.69, Validation accuracy 50.88
Epoch 30, Train loss 0.25, Train accuracy 92.46, Validation loss 2.72, Validation accuracy 50.33
Epoch 31, Train loss 0.25, Train accuracy 92.76, Validation loss 2.68, Validation accuracy 51.11
Epoch 32, Train loss 0.24, Train accuracy 92.95, Validation loss 2.71, Validation accuracy 51.02
Epoch 33, Train loss 0.22, Train accuracy 93.39, Validation loss 2.72, Validation accuracy 51.47
Epoch 34, Train loss 0.22, Train accuracy 93.63, Validation loss 2.82, Validation accuracy 50.62
Epoch 35, Train loss 0.21, Train accuracy 93.65, Validation loss 2.80, Validation accuracy 50.79
Epoch 36, Train loss 0.21, Train accuracy 93.72, Validation loss 2.79, Validation accuracy 51.39
Epoch 37, Train loss 0.20, Train accuracy 94.02, Validation loss 2.78, Validation accuracy 50.90
Epoch 38, Train loss 0.19, Train accuracy 94.20, Validation loss 2.73, Validation accuracy 51.53
Epoch 39, Train loss 0.19, Train accuracy 94.38, Validation loss 2.75, Validation accuracy 51.86
Epoch 40, Train loss 0.19, Train accuracy 94.44, Validation loss 2.77, Validation accuracy 51.66
Epoch 41, Train loss 0.18, Train accuracy 94.68, Validation loss 2.82, Validation accuracy 51.83
Epoch 42, Train loss 0.18, Train accuracy 94.69, Validation loss 2.78, Validation accuracy 51.38
Epoch 43, Train loss 0.17, Train accuracy 94.85, Validation loss 2.80, Validation accuracy 51.58
Epoch 44, Train loss 0.17, Train accuracy 94.97, Validation loss 2.83, Validation accuracy 51.64
Epoch 45, Train loss 0.16, Train accuracy 95.25, Validation loss 2.78, Validation accuracy 52.20
Epoch 46, Train loss 0.16, Train accuracy 95.19, Validation loss 2.84, Validation accuracy 51.29
Epoch 47, Train loss 0.16, Train accuracy 95.17, Validation loss 2.84, Validation accuracy 51.14
Epoch 48, Train loss 0.16, Train accuracy 95.38, Validation loss 2.75, Validation accuracy 52.35
Epoch 49, Train loss 0.16, Train accuracy 95.40, Validation loss 2.85, Validation accuracy 51.72
Epoch 50, Train loss 0.16, Train accuracy 95.37, Validation loss 2.88, Validation accuracy 51.23
Epoch 51, Train loss 0.15, Train accuracy 95.46, Validation loss 2.81, Validation accuracy 51.93
Epoch 52, Train loss 0.14, Train accuracy 95.76, Validation loss 2.83, Validation accuracy 51.52
Epoch 53, Train loss 0.15, Train accuracy 95.65, Validation loss 2.79, Validation accuracy 51.83
Epoch 54, Train loss 0.14, Train accuracy 95.82, Validation loss 2.86, Validation accuracy 51.29
Epoch 55, Train loss 0.14, Train accuracy 95.70, Validation loss 2.79, Validation accuracy 52.57
Epoch 56, Train loss 0.14, Train accuracy 95.77, Validation loss 2.85, Validation accuracy 51.20
Epoch 57, Train loss 0.14, Train accuracy 95.73, Validation loss 2.83, Validation accuracy 51.69
Epoch 58, Train loss 0.13, Train accuracy 96.13, Validation loss 2.81, Validation accuracy 52.53
Epoch 59, Train loss 0.13, Train accuracy 96.06, Validation loss 2.86, Validation accuracy 51.57
Epoch 60, Train loss 0.14, Train accuracy 95.95, Validation loss 2.88, Validation accuracy 51.48
Epoch 61, Train loss 0.13, Train accuracy 96.06, Validation loss 2.89, Validation accuracy 51.68
Epoch 62, Train loss 0.13, Train accuracy 96.28, Validation loss 2.89, Validation accuracy 52.14
Epoch 63, Train loss 0.14, Train accuracy 95.97, Validation loss 2.89, Validation accuracy 51.48
Epoch 64, Train loss 0.13, Train accuracy 96.11, Validation loss 2.89, Validation accuracy 51.00
Epoch 65, Train loss 0.13, Train accuracy 96.20, Validation loss 2.81, Validation accuracy 51.87
Epoch 66, Train loss 0.13, Train accuracy 96.26, Validation loss 2.86, Validation accuracy 52.02
Best Validation Accuracy 52.57, Epoch: 55, Training Time: 8775.67s
